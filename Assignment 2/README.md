# DH150 Assignment 2: Usability Testing

# Documentation:

## Step 0: 
Myucla.edu serves as an information gateway for anything UCLA related and class planning website for students at UCLA. Myucla.edu provides many services for anyone that needs to find information about the school. The class planner specifically provides information on the different classes the student needs. 

UCLA students conducted an onsite pilot usability test using a live version of myucla.edu located on the test administrator’s laptop. Two laptops using the Photobooth software captured the participant’s face and comments, while the Quicktime Screenrecording software captured the navigation choices and the live website. The test administrator and data logger were present in the testing room. The session captured each participant’s navigational choices, task completion rates, comments, overall satisfaction ratings, questions and feedback. The session was located in a quiet room at 708 Hilgard Avenue, Los Angeles, CA 90024. 

The rationale behind the UT for this website was because of the main user functionalities that I felt could be better. From looking at the list of the heuristic reviews, I felt that the website lacked in the flexibility and efficiency of use, consistency and standards, and the aesthetic and minimalist design. Therefore, I was hoping the UT can help find evidence that these specific areas of the website can be improved. The purpose of the usability testing aims to find out how to improve the web/app from user’s perspective.

The test administrator contacted and recruited participants from the list of students that have not used this website before. The test administrator sent a text to an attendee informing them of the test logistics and requesting their availability and participation. The participant responded with an appropriate date and time. The UT session lasted approximately thirty minutes. During the session, the test administrator explained the test session and asked the participant to fill out a brief background questionnaire and pretest questionannaire that asked background information about the website and whether or not the participant have used the website before. The administrator read the task scenarios and asked the participant to try to find the information on the website. 

After each task, the administrator asked the participant to complete the post-task scenario subjective measures that included: 
•	How easy or difficult it was to perform the different tasks.
•	How much time was needed to complete the task.
•	How likely you think you would do this task.

After the last task was completed, the test administrator asked the participant to rate the system usability by asking several questions regarding the usability of the website by using a 7-point Likert scale (Strongly Disagree to Strongly Agree) for eight subjective measures including:
## •	Ease of use
•	Frequency of use
•	Difficulty to keep track of location in website
•	Learn ability  - how easy it would be for most users to learn to use the website
•	Information facilitation – how quickly participant could find information
•	Look & feel appeal – homepage’s content makes me want to explore the site further
•	Site content – site’s content would keep me coming back 

In addition, the test administrator asked about product satisfaction such as the aesthetic of the website and how the participant felt when looking at the website. 

## Step 1: Test Materials
https://forms.gle/XE8Yh3xmRgxPa93F6

## Step 2: Video

Part 1 of Screen-recording 
https://www.youtube.com/watch?v=572J0g36EaI


Part 2 of Screen-recording
https://www.youtube.com/watch?v=mx8yX95eh4s


Part 1 of Video of reactions and audio:
https://www.youtube.com/watch?v=gIz0_eleLbc


Part 2 of Video of reactions and audio:
https://www.youtube.com/watch?v=_lbBM8g_sZs


I had to split the videos in half for each because the file was too big. 

## Step 3: Reflection

What I learned during the pilot test is that there could be many things that you might not expect the user to do and might be very unexpected, but the best thing to do is to go with the flow and make sure the user feels comfortable. Additionally, the pilot testing might take longer than expected because the user might be stuck on a certain question longer than others. What went well during the pilot testing was that the user did not give up and was able to go through all the tasks without feeling bad that they did not get every question. I wanted to make sure the user was comfortable and right, and that went really well. What did not go so well was the fact that I did not expect the user to take as long as she did because I told her beforehand that it would only take about 15 minutes. She was confused about some tasks but she just skipped the ones that she did not know and moved on. How I want to improve the UT in the future is that I hope to have more tasks that represented different heuristics and give the user more options for some of the questions. Additionally, I would be more prepared with the screen recording because it was difficult to find a software that would record for more than 10 minutes. Overall, it was a great pilot UT session. 

